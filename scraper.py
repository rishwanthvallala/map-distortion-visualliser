import requests
from bs4 import BeautifulSoup
import pprint
import os

def scrape_and_save_projections():
    """
    Scrapes the PROJ documentation and saves the projection list
    to a Python file named scraped_projections.py.
    """
    url = "https://proj.org/en/stable/operations/projections/index.html"
    output_filename = "scraped_projections.py"
    
    try:
        print("Fetching data from the website...")
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        print("Successfully fetched data.")
    except requests.exceptions.RequestException as e:
        print(f"Error: Could not fetch the URL. {e}")
        return

    print("Parsing the list of projections...")
    soup = BeautifulSoup(response.content, 'html.parser')
    
    tree_wrapper = soup.find('div', class_='toctree-wrapper')
    if not tree_wrapper:
        print("Error: Could not find the div with class 'toctree-wrapper'.")
        return

    projection_list = tree_wrapper.find('ul')
    if not projection_list:
        print("Error: Could not find the projection list (<ul>) inside the wrapper.")
        return
        
    projections_to_save = {}

    # --- START OF THE FIX ---
    for item in projection_list.find_all('li'):
        link = item.find('a')
        
        # Check if the link tag exists and has an 'href' attribute first.
        if link and link.has_attr('href'):
            # If it does, NOW we can safely get the value and check it.
            href = link['href']
            
            if href.endswith('.html'):
                long_name = link.text.strip()
                short_code = os.path.splitext(href)[0]
                
                # Exclude the final "all_images" link
                if short_code == "all_images":
                    continue

                proj_string = f"+proj={short_code} +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
                projections_to_save[long_name] = proj_string
    # --- END OF THE FIX ---

    if not projections_to_save:
        print("Scraping complete, but no projections were found.")
        return

    print(f"\n--- SCRAPING COMPLETE ---")
    
    try:
        with open(output_filename, "w", encoding="utf-8") as f:
            f.write("# This file was auto-generated by scrape_projections.py\n")
            f.write("# It contains the dictionary of scraped PROJ projections.\n\n")
            formatted_dict = pprint.pformat(projections_to_save, indent=2)
            f.write(f"projections = {formatted_dict}\n")
        print(f"Successfully saved {len(projections_to_save)} projections to '{output_filename}'")
    except IOError as e:
        print(f"Error: Could not write to file '{output_filename}'. {e}")

if __name__ == "__main__":
    scrape_and_save_projections()